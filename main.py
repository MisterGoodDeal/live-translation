import whisper
import sounddevice as sd
import numpy as np
import queue
import sys
import asyncio
import socketio
from fastapi import FastAPI
import uvicorn
import json
import os
import subprocess
import time
import webbrowser
import platform
import signal
import psutil

# ----------------------
# CONFIG
# ----------------------
CONFIG_FILE = "config.json"
FRONT_URL = "http://localhost:3000"

# Configuration par d√©faut
DEFAULT_CONFIG = {
    "model_name": "small",
    "sample_rate": 16000,
    "chunk_duration": 2,
    "volume_threshold": 0.01,
    "selected_microphone_id": None,
    "use_gpu": False,
    "force_mps": False  # Option pour forcer MPS sur Mac (peut causer des erreurs)
}

def kill_process_tree(proc):
    """Tue un process et tous ses enfants"""
    try:
        parent = psutil.Process(proc.pid)
        children = parent.children(recursive=True)
        for child in children:
            child.kill()
        parent.kill()
    except Exception as e:
        print(f"‚ùå Erreur en tuant le process: {e}")

def load_config():
    """Charge la configuration depuis le fichier JSON"""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                config = json.load(f)
                print(f"‚úÖ Configuration charg√©e depuis {CONFIG_FILE}")
                return config
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement de la config: {e}")
    
    print(f"üìù Cr√©ation de la configuration par d√©faut")
    return DEFAULT_CONFIG.copy()

def save_config(config):
    """Sauvegarde la configuration dans le fichier JSON"""
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"üíæ Configuration sauvegard√©e dans {CONFIG_FILE}")
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde: {e}")

# Charger la configuration
config = load_config()
MODEL_NAME = config["model_name"]
SAMPLE_RATE = config["sample_rate"]
CHUNK_DURATION = config["chunk_duration"]
VOLUME_THRESHOLD = config["volume_threshold"]
SELECTED_MICROPHONE_ID = config["selected_microphone_id"]
USE_GPU = config["use_gpu"]
FORCE_MPS = config.get("force_mps", False)

# √âtat de la transcription
TRANSCRIPTION_ACTIVE = False
AUDIO_LOOP_RUNNING = False

# ----------------------
# D√©tection GPU
# ----------------------
def detect_gpu_device():
    """D√©tecte le type de GPU disponible"""
    try:
        import torch
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if FORCE_MPS:
                print("‚ö†Ô∏è MPS forc√© (peut causer des erreurs avec Whisper)")
                return "mps"
            else:
                # MPS a des probl√®mes de compatibilit√© avec Whisper
                # On force le CPU pour Mac pour √©viter les erreurs
                print("‚ö†Ô∏è MPS d√©tect√© mais d√©sactiv√© pour Whisper (probl√®mes de compatibilit√©)")
                return "cpu"
        else:
            return "cpu"
    except ImportError:
        return "cpu"

# ----------------------
# INIT Whisper
# ----------------------
print(f"Loading Whisper model '{MODEL_NAME}'...")

# Afficher les informations GPU
gpu_device = detect_gpu_device()
print(f"üîç GPU d√©tect√©: {gpu_device.upper()}")
if gpu_device == "cuda":
    try:
        import torch
        print(f"   - Nom: {torch.cuda.get_device_name(0)}")
        print(f"   - M√©moire: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    except:
        pass
elif gpu_device == "mps":
    print("   - Metal Performance Shaders (Mac)")

if USE_GPU:
    print(f"üéÆ Configuration GPU: {'Activ√©' if USE_GPU else 'D√©sactiv√©'}")
    
    if gpu_device != "cpu":
        print(f"üéÆ Tentative de chargement avec acc√©l√©ration {gpu_device.upper()}...")
        try:
            model = whisper.load_model(MODEL_NAME, device=gpu_device)
            print(f"‚úÖ Mod√®le charg√© avec succ√®s sur {gpu_device.upper()}")
        except Exception as e:
            print(f"‚ö†Ô∏è Impossible de charger sur {gpu_device.upper()}: {e}")
            print("üîÑ Fallback vers CPU...")
            model = whisper.load_model(MODEL_NAME, device="cpu")
            print("‚úÖ Mod√®le charg√© sur CPU")
    else:
        print("‚ö†Ô∏è Aucun GPU d√©tect√©, utilisation du CPU")
        model = whisper.load_model(MODEL_NAME, device="cpu")
        print("üíª Mod√®le charg√© sur CPU")
else:
    model = whisper.load_model(MODEL_NAME, device="cpu")
    print("üíª Mod√®le charg√© sur CPU")

audio_queue = queue.Queue()

# ----------------------
# SOCKET.IO
# ----------------------
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*')
app = FastAPI()
app_sio = socketio.ASGIApp(sio, app)

# ----------------------
# Fonctions utilitaires
# ----------------------
def callback(indata, frames, time, status):
    if status:
        asyncio.create_task(send_log(f"‚ö†Ô∏è Audio status: {status}"))
    audio_queue.put(indata.copy())

def validate_microphone_id(mic_id):
    """Valide qu'un microphone ID existe"""
    try:
        devices = sd.query_devices()
        if 0 <= mic_id < len(devices) and devices[mic_id]['max_input_channels'] > 0:
            return True
        return False
    except Exception:
        return False

def has_speech(audio):
    rms = np.sqrt(np.mean(np.square(audio)))
    return rms > VOLUME_THRESHOLD

async def send_log(message: str):
    print(message, flush=True)
    await sio.emit('logs', {'message': message})

def get_available_microphones():
    """R√©cup√®re la liste des microphones disponibles"""
    try:
        devices = sd.query_devices()
        microphones = []
        
        for i, device in enumerate(devices):
            if device['max_input_channels'] > 0:  # C'est un p√©riph√©rique d'entr√©e
                microphones.append({
                    'id': i,
                    'name': device['name'],
                    'channels': device['max_input_channels'],
                    'sample_rate': device['default_samplerate']
                })
        
        return microphones
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des microphones: {e}")
        return []

# ----------------------
# Loop audio principale
# ----------------------
async def audio_loop():
    global TRANSCRIPTION_ACTIVE, AUDIO_LOOP_RUNNING
    buffer = np.zeros((0, 1), dtype=np.float32)
    
    print("üéôÔ∏è Boucle audio d√©marr√©e, en attente du microphone...")
    AUDIO_LOOP_RUNNING = True
    
    try:
        # Attendre qu'un microphone soit s√©lectionn√©
        while SELECTED_MICROPHONE_ID is None:
            await asyncio.sleep(1)
            
        print(f"üéôÔ∏è Utilisation du microphone ID {SELECTED_MICROPHONE_ID}")
        
        with sd.InputStream(
            samplerate=SAMPLE_RATE, 
            channels=1, 
            callback=callback,
            device=SELECTED_MICROPHONE_ID
        ):
            print("üéôÔ∏è Micro OK ! Pr√™t √† traduire...")
            while True:
                try:
                    # Utiliser un timeout plus court pour √™tre plus r√©actif
                    data = audio_queue.get(timeout=0.1)
                except queue.Empty:
                    await asyncio.sleep(0.01)
                    continue

                buffer = np.concatenate([buffer, data])
                duration = len(buffer) / SAMPLE_RATE
                rms = np.sqrt(np.mean(np.square(buffer.flatten())))
                
                # Afficher les logs seulement si la transcription est active et qu'il y a de l'activit√©
                if TRANSCRIPTION_ACTIVE and rms > VOLUME_THRESHOLD:
                    await send_log(f"Buffer: {duration:.2f}s | RMS: {rms:.4f}")

                if duration >= CHUNK_DURATION:
                    audio_data = buffer.flatten()

                    if not has_speech(audio_data):
                        if TRANSCRIPTION_ACTIVE:
                            await send_log("üîá Silence d√©tect√©, chunk ignor√©")
                        buffer = np.zeros((0, 1), dtype=np.float32)
                        continue

                    # Traiter seulement si la transcription est active
                    if TRANSCRIPTION_ACTIVE:
                        await send_log("‚è≥ Processing chunk...")
                        result = model.transcribe(
                            audio_data,
                            task="translate",
                            language="fr",
                            fp16=False
                        )

                        translated_text = result["text"].strip()
                        if translated_text:  # Envoyer seulement si il y a du texte
                            await send_log(f"üí¨ Traduction: {translated_text}")
                            # envoyer la traduction √† tous les clients
                            await sio.emit('translation', {'text': translated_text})

                    buffer = np.zeros((0, 1), dtype=np.float32)
    except asyncio.CancelledError:
        print("üéôÔ∏è Boucle audio annul√©e")
        raise  # Re-raise pour que la t√¢che soit marqu√©e comme annul√©e
    except Exception as e:
        print(f"‚ùå Erreur dans la boucle audio: {e}")
    finally:
        print("üéôÔ∏è Boucle audio arr√™t√©e")
        AUDIO_LOOP_RUNNING = False

# ----------------------
# SOCKET.IO EVENTS
# ----------------------
@sio.event
async def connect(sid, environ):
    print(f"‚úÖ Client connect√©: {sid}")
    await send_log(f"‚úÖ Nouveau client connect√©: {sid}")
    
    # Envoyer la configuration actuelle au client
    await sio.emit('config', {
        'model_name': config['model_name'],
        'sample_rate': config['sample_rate'],
        'chunk_duration': config['chunk_duration'],
        'volume_threshold': config['volume_threshold'],
        'selected_microphone_id': config['selected_microphone_id'],
        'use_gpu': config['use_gpu']
    }, room=sid)

@sio.event
async def disconnect(sid):
    print(f"‚ùå Client d√©connect√©: {sid}")
    await send_log(f"‚ùå Client d√©connect√©: {sid}")

@sio.event
async def ping(sid, data):
    """R√©pondre au ping du client avec un pong"""
    timestamp = data.get('timestamp', 0)
    await sio.emit('pong', {'timestamp': timestamp}, room=sid)
    await send_log(f"üèì Ping re√ßu de {sid}, pong envoy√©")

@sio.event
async def get_microphones(sid):
    """R√©cup√®re et envoie la liste des microphones disponibles"""
    await send_log("üé§ R√©cup√©ration de la liste des microphones...")
    microphones = get_available_microphones()
    
    await sio.emit('microphones', {
        'microphones': microphones,
        'count': len(microphones)
    }, room=sid)
    
    await send_log(f"üé§ {len(microphones)} microphone(s) trouv√©(s)")
    for mic in microphones:
        await send_log(f"  - {mic['name']} (ID: {mic['id']}, {mic['channels']} canal(s), {mic['sample_rate']}Hz)")

@sio.event
async def set_microphone(sid, data):
    """Configure le microphone s√©lectionn√©"""
    global SELECTED_MICROPHONE_ID, config
    
    mic_id = data.get('id')
    if mic_id is None:
        await send_log("‚ùå ID de microphone manquant")
        return
    
    if not validate_microphone_id(mic_id):
        await send_log(f"‚ùå Microphone ID {mic_id} invalide")
        return
    
    # R√©cup√©rer les infos du microphone
    devices = sd.query_devices()
    mic_info = devices[mic_id]
    
    SELECTED_MICROPHONE_ID = mic_id
    config["selected_microphone_id"] = mic_id
    save_config(config)
    
    await send_log(f"üé§ Microphone s√©lectionn√©: {mic_info['name']} (ID: {mic_id})")
    await send_log(f"   - Canaux: {mic_info['max_input_channels']}")
    await send_log(f"   - Fr√©quence: {mic_info['default_samplerate']}Hz")
    await send_log(f"üíæ Configuration sauvegard√©e")

@sio.event
async def update_config(sid, data):
    """Met √† jour la configuration"""
    global config, VOLUME_THRESHOLD, CHUNK_DURATION
    
    updated = False
    
    if 'volume_threshold' in data:
        config["volume_threshold"] = float(data['volume_threshold'])
        VOLUME_THRESHOLD = config["volume_threshold"]
        await send_log(f"üîä Seuil de volume mis √† jour: {VOLUME_THRESHOLD}")
        updated = True
    
    if 'chunk_duration' in data:
        config["chunk_duration"] = float(data['chunk_duration'])
        CHUNK_DURATION = config["chunk_duration"]
        await send_log(f"‚è±Ô∏è Dur√©e des chunks mise √† jour: {CHUNK_DURATION}s")
        updated = True
    
    if 'sample_rate' in data:
        config["sample_rate"] = int(data['sample_rate'])
        SAMPLE_RATE = config["sample_rate"]
        await send_log(f"üîä Fr√©quence d'√©chantillonnage mise √† jour: {SAMPLE_RATE}Hz")
        updated = True

    if 'model_name' in data:
        config["model_name"] = data['model_name']
        MODEL_NAME = config["model_name"]
        await send_log(f"üîä Mod√®le Whisper mise √† jour: {MODEL_NAME}")
        updated = True

    if 'use_gpu' in data:
        config["use_gpu"] = bool(data['use_gpu'])
        USE_GPU = config["use_gpu"]
        await send_log(f"üéÆ Utilisation GPU mise √† jour: {'Activ√©' if USE_GPU else 'D√©sactiv√©'}")
        await send_log("‚ö†Ô∏è Red√©marrez l'application pour que les changements GPU prennent effet")
        updated = True
    
    if updated:
        save_config(config)
        await send_log("üíæ Configuration sauvegard√©e")

@sio.event
async def get_config(sid):
    """R√©cup√®re la configuration actuelle"""
    await sio.emit('config', {
        'model_name': config["model_name"],
        'sample_rate': config["sample_rate"],
        'chunk_duration': config["chunk_duration"],
        'volume_threshold': config["volume_threshold"],
        'selected_microphone_id': config["selected_microphone_id"],
        'use_gpu': config["use_gpu"]
    }, room=sid)

@sio.event
async def start_translation(sid):
    """D√©marre la transcription"""
    global TRANSCRIPTION_ACTIVE, audio_task
    
    if SELECTED_MICROPHONE_ID is None:
        await send_log("‚ùå Aucun microphone s√©lectionn√©")
        await sio.emit('translation_status', {'active': False, 'error': 'No microphone selected'}, room=sid)
        return
    
    TRANSCRIPTION_ACTIVE = True
    
    # D√©marrer la boucle audio si elle n'est pas d√©j√† d√©marr√©e
    if 'audio_task' not in globals() or audio_task.done():
        audio_task = asyncio.create_task(audio_loop())
        print("üéôÔ∏è Boucle audio d√©marr√©e")
    
    await send_log("üé§ Transcription d√©marr√©e")
    await sio.emit('translation_status', {'active': True, 'message': 'Transcription started'}, room=sid)

@sio.event
async def stop_translation(sid):
    """Arr√™te la transcription"""
    global TRANSCRIPTION_ACTIVE, AUDIO_LOOP_RUNNING, audio_task
    
    print("‚èπÔ∏è Arr√™t de la transcription demand√©...")
    TRANSCRIPTION_ACTIVE = False
    AUDIO_LOOP_RUNNING = False
    
    # Arr√™ter compl√®tement la t√¢che audio
    if 'audio_task' in globals() and audio_task and not audio_task.done():
        audio_task.cancel()
        try:
            await audio_task
        except asyncio.CancelledError:
            pass
    
    # Vider la queue audio
    while not audio_queue.empty():
        try:
            audio_queue.get_nowait()
        except queue.Empty:
            break
    
    await send_log("‚èπÔ∏è Transcription arr√™t√©e")
    await sio.emit('translation_status', {'active': False, 'message': 'Transcription stopped'}, room=sid)
    print("‚úÖ Transcription arr√™t√©e avec succ√®s")

# ----------------------
# ROUTES HTTP
# ----------------------
@app.get("/")
async def root():
    return {"status": "ok", "message": "Socket.IO STT server running"}

# ----------------------
# Lancer le serveur
# ----------------------
async def main():
    """Fonction principale qui lance le serveur et la boucle audio"""
    # Configurer uvicorn
    config = uvicorn.Config(app_sio, host="0.0.0.0", port=8000)
    server = uvicorn.Server(config)
    
    # Lancer la boucle audio en arri√®re-plan (sans attendre)
    asyncio.create_task(audio_loop())
    
    try:
        await server.serve()
    except KeyboardInterrupt:
        print("Arr√™t du serveur...")

if __name__ == "__main__":
    print("üöÄ Lancement du front Next.js...")
    next_process = subprocess.Popen(
        ["npm", "run", "start"],
        cwd="live-translation-front",
        preexec_fn=os.setsid if platform.system() != "Windows" else None
    )

    def shutdown_handler(sig, frame):
        print("\nüõë Arr√™t en cours... (backend + Next.js)")
        kill_process_tree(next_process)
        sys.exit(0)

    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    print("‚è≥ Attente du front (3s)...")
    time.sleep(3)

    print(f"üåç Ouverture du navigateur sur {FRONT_URL}")
    webbrowser.open(FRONT_URL)

    # D√©marrer le serveur avec une configuration qui g√®re mieux les interruptions
    uvicorn.run(
        app_sio, 
        host="0.0.0.0", 
        port=8000, 
        log_level="info",
        access_log=False,  # R√©duire les logs pour moins de spam
        loop="asyncio"     # Forcer l'utilisation d'asyncio
    )
